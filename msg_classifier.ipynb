{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "from collections import OrderedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "jieba.set_dictionary(\"dict.txt.big\")\n",
    "stop_words_path = \"stop_words.txt\"\n",
    "jieba.analyse.set_stop_words(stop_words_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# excel to json\n",
    "def excel_to_json(excel_file_name):\n",
    "    wb = xlrd.open_workbook(excel_file_name)\n",
    "    sh = wb.sheet_by_index(0)\n",
    "    \n",
    "    message_all = OrderedDict()\n",
    "    message_all['X'] = []\n",
    "    message_all['y'] = []\n",
    "    \n",
    "    for rownum in range(1, sh.nrows):\n",
    "        row_values = sh.row_values(rownum)\n",
    "        msg = row_values[2]\n",
    "        label = row_values[3]\n",
    "        if msg != '' and label != '':\n",
    "            message_all['X'].append(msg)\n",
    "            message_all['y'].append(label)\n",
    "    \n",
    "    return message_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_class_keyword(label, message_all):\n",
    "    msg_label = np.array(message_all['X'])[np.array(message_all['y'])==label]\n",
    "    combined_msg = ''\n",
    "    for m in msg_label:\n",
    "        msg_without_url = re.sub(\"(?P<url>https?://[^\\s]+)\",'', m)    \n",
    "        combined_msg += msg_without_url\n",
    "    class_keyword = jieba.analyse.extract_tags(combined_msg, 200)\n",
    "    return class_keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 製作特徵向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TextMining:\n",
    "    def __init__(self):\n",
    "        self.keyword_dict = None\n",
    "    def get_keyword_dict(self,refresh=False):\n",
    "        if self.keyword_dict == None or refresh == True:\n",
    "            file_name = 'keyword_2.json'\n",
    "            if os.path.isfile(file_name):\n",
    "                with open(file_name,'r') as infile:\n",
    "                    keyword_file = json.load(infile, object_pairs_hook=OrderedDict)\n",
    "                self.keyword_dict = keyword_file\n",
    "            else:\n",
    "                print file_name+\" doesn't exist\"\n",
    "                return \n",
    "        return self.keyword_dict\n",
    "    def _make_ML_X(self,msg_list,print_out=False):\n",
    "        key_dict = self.get_keyword_dict()\n",
    "        ML_X = []\n",
    "        for msg in msg_list:\n",
    "            tmp = []\n",
    "            has_url = 1 if len(re.findall(\"(?P<url>https?://[^\\s]+)\", msg))>0 else 0\n",
    "            msg_len = len(msg)\n",
    "            tmp.append(has_url)\n",
    "            tmp.append(msg_len)\n",
    "            if print_out:\n",
    "                print 'has_url : ',has_url\n",
    "                print 'msg_len : ',msg_len\n",
    "            for k in key_dict:\n",
    "                message_jieba = jieba.analyse.extract_tags(msg,0)\n",
    "                match = list(set(message_jieba).intersection(key_dict[k]))\n",
    "                if print_out:\n",
    "                    print 'match '+k+' : ',','.join(match)\n",
    "                tmp.append(len(match))\n",
    "            ML_X.append(tmp)\n",
    "        return ML_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 分類器 with different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, X_train, y_train, algorithm):\n",
    "        self.alg = algorithm\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = None\n",
    "    def _predict(self, test_X):\n",
    "        return self.get_model().predict(test_X)\n",
    "    def get_model(self):\n",
    "        if self.model == None :\n",
    "            if self.alg == \"lg\":\n",
    "                clf = LogisticRegression()\n",
    "            elif self.alg == \"tree\":\n",
    "                clf = tree.DecisionTreeClassifier()\n",
    "            elif self.alg == \"svm\":\n",
    "                clf = svm.SVC()\n",
    "            else:\n",
    "                print \"wrong algorithm name : \", self.alg\n",
    "                return\n",
    "            self.model = clf.fit(self.X_train,self.y_train)\n",
    "        return self.model\n",
    "    def accuracy(self, X_test, y_test):\n",
    "        model = self.get_model()\n",
    "        if model is not None:\n",
    "            prediction = model.predict(X_test)\n",
    "            accuracy = np.mean(np.array(prediction)==np.array(y_test))\n",
    "            correct_idx = np.where(np.array(prediction)==np.array(y_test))[0]\n",
    "            incorrect_idx = np.where(np.array(prediction)!=np.array(y_test))[0]\n",
    "            return accuracy, correct_idx, incorrect_idx\n",
    "        else:\n",
    "            print \"model:None has no accuracy\"\n",
    "            return\n",
    "    def _classification_report(self, X_test, y_test):\n",
    "        model = self.get_model()\n",
    "        class_names = ['class 0', 'class 1', 'class 2']\n",
    "        if model is not None:\n",
    "            prediction = model.predict(X_test)\n",
    "            return classification_report(y_test, prediction, target_names=class_names)\n",
    "        else:\n",
    "            print \"model:None has no classification_report\"\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "message_all = excel_to_json('2017_line.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/q1/sy8zj9z12v792k86g84xby1r0000gn/T/jieba.cache\n",
      "Loading model cost 1.890 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "X = TextMining()._make_ML_X(message_all['X'],print_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X,columns = ['url','len','obj_topic','push','action','sub_emotion','sub_topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class : 1.0\n",
      "message : 7-11圖片條碼換大熱拿鐵，一支手機一次，家裡有幾支手機就可以換幾杯拿鐵。\n",
      "把這個圖片存下來，可以去7-11換一杯大熱拿\n",
      "要開圖片給他刷條碼\n",
      "2/28前要換掉\n",
      "\n",
      "記住！是7-11唷\n"
     ]
    }
   ],
   "source": [
    "# Line訊息\n",
    "print \"class : %s\" % message_all['y'][0]\n",
    "print \"message : %s\" % message_all['X'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>len</th>\n",
       "      <th>obj_topic</th>\n",
       "      <th>push</th>\n",
       "      <th>action</th>\n",
       "      <th>sub_emotion</th>\n",
       "      <th>sub_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url  len  obj_topic  push  action  sub_emotion  sub_topic\n",
       "0    0   90          1     0       1            0          0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特徵向量\n",
    "df[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Imbalanced Data - Training/Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, message_all['y'], test_size=0.2, stratify=message_all['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.60449438  0.11460674  0.28089888] 445\n",
      "[ 0.60714286  0.11607143  0.27678571] 112\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(y_train)/float(len(y_train)),len(y_train)\n",
    "print np.bincount(y_test)/float(len(y_test)),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "lg_model = lg.fit(X_train,y_train)\n",
    "prediction = lg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Imbalanced Data - Classifier evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.883928571429\n",
      "correct_idx: [  0   2   3   4   5   6   7   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  30  31  32  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  66  67  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  83  84  85  86  87  88  90  91  92  93  94  95  96  97  98\n",
      "  99 101 103 104 105 106 108 110 111]\n",
      "incorrect_idx: [  1   8  28  29  33  46  68  82  89 100 102 107 109]\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(np.array(prediction)==np.array(y_test))\n",
    "correct_idx = np.where(np.array(prediction)==np.array(y_test))[0]\n",
    "incorrect_idx = np.where(np.array(prediction)!=np.array(y_test))[0]\n",
    "print \"accuracy:\",accuracy\n",
    "print \"correct_idx:\",correct_idx\n",
    "print \"incorrect_idx:\",incorrect_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.93      0.94      0.93        68\n",
      "    class 1       0.82      0.69      0.75        13\n",
      "    class 2       0.81      0.84      0.83        31\n",
      "\n",
      "avg / total       0.88      0.88      0.88       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print classification_report(y_test, prediction, target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Balanced Data ( using under-sampling approach ) - Training/Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np_X = np.array(X)\n",
    "np_y = np.array([int(i) for i in message_all['y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_0, y_0 = resample(np_X[np_y==0], np_y[np_y==0],n_samples=61,random_state=0)\n",
    "X_1, y_1 = resample(np_X[np_y==1], np_y[np_y==1],n_samples=61,random_state=0)\n",
    "X_2, y_2 = resample(np_X[np_y==2], np_y[np_y==2],n_samples=61,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_balance = np.concatenate((X_0,X_1,X_2))\n",
    "y_balance = np.concatenate((y_0,y_1,y_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_balance, y_balance, test_size=0.2, stratify=y_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33561644  0.32876712  0.33561644] 146\n",
      "[ 0.32432432  0.35135135  0.32432432] 37\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(y_train_b)/float(len(y_train_b)),len(y_train_b)\n",
    "print np.bincount(y_test_b)/float(len(y_test_b)),len(y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Balanced Data - Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_lg = Classifier(X_train_b,y_train_b,\"lg\")\n",
    "accuracy_lg, correct_idx_lg,incorrect_idx_lg = clf_lg.accuracy(X_test_b,y_test_b)\n",
    "clf_report_lg = clf_lg._classification_report(X_test_b,y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_tree = Classifier(X_train_b,y_train_b,\"tree\")\n",
    "accuracy_tree, correct_idx_tree,incorrect_idx_tree = clf_tree.accuracy(X_test_b,y_test_b)\n",
    "clf_report_tree = clf_tree._classification_report(X_test_b,y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_svm = Classifier(X_train_b,y_train_b,\"svm\")\n",
    "accuracy_svm, correct_idx_svm,incorrect_idx_svm = clf_svm.accuracy(X_test_b,y_test_b)\n",
    "clf_report_svm = clf_svm._classification_report(X_test_b,y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.945945945946\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.86      1.00      0.92        12\n",
      "    class 1       1.00      0.92      0.96        13\n",
      "    class 2       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.95      0.95      0.95        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print accuracy_lg\n",
    "print clf_report_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972972972973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00        12\n",
      "    class 1       0.93      1.00      0.96        13\n",
      "    class 2       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.97      0.97      0.97        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print accuracy_tree\n",
    "print clf_report_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756756756757\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00        12\n",
      "    class 1       0.61      0.85      0.71        13\n",
      "    class 2       0.71      0.42      0.53        12\n",
      "\n",
      "avg / total       0.77      0.76      0.74        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print accuracy_svm\n",
    "print clf_report_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_lg_model.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_lg.get_model(), 'classifier_lg_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('clf_lg_model_cPickle.pkl', 'wb') as fid:\n",
    "    cPickle.dump(clf_lg.get_model(), fid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qq,見效,weixin,mp,na321dZIYdaAoNGkoKG0ZA,無數,太棒了,方子,救人,咳嗽,一天\n"
     ]
    }
   ],
   "source": [
    "print ','.join(jieba.analyse.extract_tags(message_all['X'][190], 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
